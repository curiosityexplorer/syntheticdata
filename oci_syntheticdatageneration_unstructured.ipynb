{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a9c693-000a-4cdf-b0c4-6e1a2acd8cd8",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140fad68-fce3-4b21-be28-7225cbeba1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.9\n"
     ]
    }
   ],
   "source": [
    "#Import ADS Library:\n",
    "#The code imports the ads library, which is Oracle's Accelerated Data Science library. This library provides various tools and functionalities for data science tasks within Oracle Cloud Infrastructure (OCI).\n",
    "#Print ADS Library Version:\n",
    "#The print(ads.__version__) command outputs the version of the ads library currently installed. This is useful for debugging, ensuring compatibility, and verifying that the correct version of the library is being used.\n",
    "import ads\n",
    "print(ads.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea8a0ee-5ecd-4dfc-86f6-cc640dce940c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oracle-ads in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (2.11.9)\n",
      "Collecting oracle-ads\n",
      "  Using cached oracle_ads-2.11.15-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: PyYAML>=6 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (6.0.1)\n",
      "Requirement already satisfied: asteval>=0.9.25 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (0.9.33)\n",
      "Requirement already satisfied: cerberus>=1.3.4 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (1.3.5)\n",
      "Requirement already satisfied: cloudpickle>=1.6.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=0.8.7 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (2023.12.2)\n",
      "Requirement already satisfied: gitpython>=3.1.2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (3.1.43)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (3.1.4)\n",
      "Requirement already satisfied: matplotlib<=3.8.4,>=3.1.3 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (3.7.5)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (1.24.3)\n",
      "Requirement already satisfied: oci>=2.125.3 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (2.127.0)\n",
      "Requirement already satisfied: ocifs>=1.1.3 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (1.3.1)\n",
      "Requirement already satisfied: pandas>1.2.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (2.0.3)\n",
      "Requirement already satisfied: psutil>=5.7.2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (5.9.5)\n",
      "Requirement already satisfied: python_jsonschema_objects>=0.3.13 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (0.5.4)\n",
      "Requirement already satisfied: requests in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (2.32.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (1.2.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oracle-ads) (4.66.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from gitpython>=3.1.2->oracle-ads) (4.0.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from jinja2>=2.11.2->oracle-ads) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle-ads) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle-ads) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle-ads) (4.52.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle-ads) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle-ads) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle-ads) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle-ads) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle-ads) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from matplotlib<=3.8.4,>=3.1.3->oracle-ads) (6.1.1)\n",
      "Requirement already satisfied: certifi in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oci>=2.125.3->oracle-ads) (2024.2.2)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=3.2.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oci>=2.125.3->oracle-ads) (42.0.5)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=17.5.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oci>=2.125.3->oracle-ads) (24.1.0)\n",
      "Requirement already satisfied: pytz>=2016.10 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oci>=2.125.3->oracle-ads) (2024.1)\n",
      "Requirement already satisfied: circuitbreaker<2.0.0,>=1.3.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from oci>=2.125.3->oracle-ads) (1.4.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from pandas>1.2.1->oracle-ads) (2024.1)\n",
      "Requirement already satisfied: inflection>=0.2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from python_jsonschema_objects>=0.3.13->oracle-ads) (0.5.1)\n",
      "Requirement already satisfied: Markdown>=2.4 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from python_jsonschema_objects>=0.3.13->oracle-ads) (3.6)\n",
      "Requirement already satisfied: jsonschema>=4.18 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from python_jsonschema_objects>=0.3.13->oracle-ads) (4.19.2)\n",
      "Requirement already satisfied: six>=1.5.2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from python_jsonschema_objects>=0.3.13->oracle-ads) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from scikit-learn>=1.0->oracle-ads) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from scikit-learn>=1.0->oracle-ads) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from scikit-learn>=1.0->oracle-ads) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from requests->oracle-ads) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from requests->oracle-ads) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from requests->oracle-ads) (2.2.1)\n",
      "Requirement already satisfied: cffi>=1.12 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from cryptography<43.0.0,>=3.2.1->oci>=2.125.3->oracle-ads) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.2->oracle-ads) (5.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib<=3.8.4,>=3.1.3->oracle-ads) (3.17.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from jsonschema>=4.18->python_jsonschema_objects>=0.3.13->oracle-ads) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from jsonschema>=4.18->python_jsonschema_objects>=0.3.13->oracle-ads) (2023.7.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from jsonschema>=4.18->python_jsonschema_objects>=0.3.13->oracle-ads) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from jsonschema>=4.18->python_jsonschema_objects>=0.3.13->oracle-ads) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from jsonschema>=4.18->python_jsonschema_objects>=0.3.13->oracle-ads) (0.10.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from Markdown>=2.4->python_jsonschema_objects>=0.3.13->oracle-ads) (7.0.1)\n",
      "Requirement already satisfied: pycparser in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from cffi>=1.12->cryptography<43.0.0,>=3.2.1->oci>=2.125.3->oracle-ads) (2.21)\n",
      "Using cached oracle_ads-2.11.15-py3-none-any.whl (22.8 MB)\n",
      "Installing collected packages: oracle-ads\n",
      "  Attempting uninstall: oracle-ads\n",
      "    Found existing installation: oracle_ads 2.11.9\n",
      "    Uninstalling oracle_ads-2.11.9:\n",
      "      Successfully uninstalled oracle_ads-2.11.9\n",
      "Successfully installed oracle-ads-2.11.15\n"
     ]
    }
   ],
   "source": [
    "# To upgrade run - The command !pip install oracle-ads --upgrade is used to upgrade the ADS library to the latest version. This ensures you have the most recent features, bug fixes, and improvements. \n",
    "! pip install oracle-ads --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a74b9b09-a8da-4856-818c-7b5bcf4a56bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import ADS Library: The code imports the ads library, which is Oracle's Accelerated Data Science library. This library provides various tools and functionalities for data science tasks within Oracle Cloud Infrastructure (OCI).\n",
    "#Import Pandas Library: The code imports the pandas library, which is a powerful data manipulation and analysis library in Python. It is commonly used for handling structured data and performing operations such as data cleaning, transformation, and analysis.\n",
    "#Set ADS Authentication Method: The ads.set_auth(\"resource_principal\") command sets the authentication method for the ADS library to use \"resource principal.\"\n",
    "#This method allows the ADS library to authenticate using the resource principal, which is an OCI identity assigned to the compute instance running the code.\n",
    "#Using resource principal authentication simplifies access to OCI services by managing credentials securely and automatically within the cloud environment.\n",
    "\n",
    "import ads\n",
    "import pandas as pd\n",
    "\n",
    "ads.set_auth(\"resource_principal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40c7a0b6-c1a8-4a2e-951b-369be0ac5625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#By following these steps, the code accesses and reads the specified CSV file from OCI Object Storage into a pandas DataFrame, enabling further data manipulation and analysis.\n",
    "\n",
    "bucket_name = \"skin_cancer_real_images\"\n",
    "namespace = \"orasenatdpltintegration01\"\n",
    "\n",
    "\n",
    "file_name = \"HAM10000_metadata.csv\"\n",
    "df = pd.read_csv(\n",
    "    f\"oci://{bucket_name}@{namespace}/{file_name}\",\n",
    "    storage_options=ads.common.auth.default_signer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b229013f-67ce-440e-96c8-2308087f5e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output of df.head() displays the first five rows of the DataFrame, along with the column names and the data contained in those rows. Here is the output in a table format:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eee1c1-1644-48dc-9ab3-7d1a562bd6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code downloads a CSV and ZIP file from OCI Object Storage, processes the data, extracts images, and uploads the images back to OCI Object Storage.\n",
    "import oci\n",
    "import ads\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "# Authenticate using ADS library\n",
    "ads.set_auth('resource_principal')\n",
    "\n",
    "# Define Object Storage details\n",
    "bucket_name = \"skin_cancer_real_images\"\n",
    "namespace = \"orasenatdpltintegration01\"\n",
    "zip_file_name = \"SkinCancerData.zip\"\n",
    "csv_file_name = \"HAM10000_metadata.csv\"\n",
    "\n",
    "# Define the local paths for the files\n",
    "local_zip_file_path = f'/home/datascience/{zip_file_name}'\n",
    "local_csv_file_path = f'/home/datascience/{csv_file_name}'\n",
    "\n",
    "# Setup Resource Principal for OCI SDK\n",
    "signer = oci.auth.signers.get_resource_principals_signer()\n",
    "\n",
    "# Initialize Object Storage Client\n",
    "object_storage_client = oci.object_storage.ObjectStorageClient(config={}, signer=signer)\n",
    "\n",
    "# Function to download a file from Object Storage\n",
    "def download_file_from_oci(bucket_name, namespace, object_name, local_file_path):\n",
    "    response = object_storage_client.get_object(namespace, bucket_name, object_name)\n",
    "    with open(local_file_path, 'wb') as f:\n",
    "        f.write(response.data.content)\n",
    "\n",
    "# Download the CSV file from Object Storage\n",
    "download_file_from_oci(bucket_name, namespace, csv_file_name, local_csv_file_path)\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(local_csv_file_path)\n",
    "\n",
    "# Save the CSV file locally (if needed)\n",
    "df.to_csv(local_csv_file_path, index=False)\n",
    "\n",
    "# Download the zip file from Object Storage\n",
    "download_file_from_oci(bucket_name, namespace, zip_file_name, local_zip_file_path)\n",
    "\n",
    "# Define the path to extract images\n",
    "extract_path = '/home/datascience/skin_cancer_real_images/'\n",
    "\n",
    "# Clear the extract path directory if it exists\n",
    "if os.path.exists(extract_path):\n",
    "    shutil.rmtree(extract_path)\n",
    "os.makedirs(extract_path)\n",
    "\n",
    "# Extract images from the zip file\n",
    "with zipfile.ZipFile(local_zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "# List and print the extracted files\n",
    "extracted_files = []\n",
    "for root, _, files in os.walk(extract_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg') or file.endswith('.png'):\n",
    "            extracted_files.append(os.path.join(root, file))\n",
    "print(f'Extracted files: {extracted_files}')\n",
    "\n",
    "# Function to upload a file to Object Storage\n",
    "def upload_file_to_oci(local_file_path, bucket_name, namespace, object_name):\n",
    "    with open(local_file_path, 'rb') as f:\n",
    "        object_storage_client.put_object(namespace, bucket_name, object_name, f)\n",
    "\n",
    "# Load images into a dictionary and upload them\n",
    "image_dict = {}\n",
    "for img_path in extracted_files:\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image_dict[os.path.basename(img_path)] = image\n",
    "\n",
    "    # Upload each image to Object Storage\n",
    "    object_name = f\"extracted_images/{os.path.basename(img_path)}\"\n",
    "    upload_file_to_oci(img_path, bucket_name, namespace, object_name)\n",
    "\n",
    "# Check the number of images extracted\n",
    "image_count = len(image_dict)\n",
    "print(f'Number of images extracted and uploaded: {image_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f7bdf2d-a6fd-4414-a150-6bfb20b551e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (0.15.2)\n",
      "Requirement already satisfied: filelock in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: numpy in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from torchvision) (2.32.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from requests->torchvision) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from requests->torchvision) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from requests->torchvision) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./conda/automlx242_p38_gpu_x86_64_v1/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Generator Model:\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "\n",
      "Discriminator Model:\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#This code defines and initializes a Generative Adversarial Network (GAN) using PyTorch, consisting of two neural network models: the Generator and the Discriminator. \n",
    "#The Generator creates synthetic images from random noise vectors, using layers of transposed convolutions, batch normalization, and ReLU activations, culminating in a Tanh activation. \n",
    "#The Discriminator evaluates images to determine if they are real or fake, using layers of convolutions, batch normalization, and Leaky ReLU activations, ending with a Sigmoid activation.\n",
    "#The input to this code includes a noise vector of size 100, which serves as the input for the Generator to create synthetic images. The output of the Generator is these synthetic images, \n",
    "#while the Discriminator outputs probability scores indicating whether the images are real or fake. The code also prints the architecture of both models to the console for verification. \n",
    "#To achieve the intended functionality, the models need to be trained with a dataset of real images, a training loop, loss functions, and optimizers.\n",
    "\n",
    "# Install torch if not already installed\n",
    "!pip install torch torchvision\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the Generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Define the Discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Hyperparameters\n",
    "nz = 100  # Size of the noise vector\n",
    "\n",
    "# Initialize models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "netG = Generator(nz).to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"Generator Model:\")\n",
    "print(netG)\n",
    "print(\"\\nDiscriminator Model:\")\n",
    "print(netD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036a456-b906-46c3-ac9f-e0cbd4b82556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code sets up and trains a Generative Adversarial Network (GAN) using PyTorch, designed to generate synthetic images. \n",
    "#The GAN consists of two models: a Generator and a Discriminator. The Generator creates synthetic images from random noise vectors, \n",
    "#while the Discriminator attempts to distinguish between real and synthetic images. \n",
    "#The code includes downloading images from Oracle Cloud Infrastructure (OCI) Object Storage, training the GAN, and then uploading the generated images back to OCI Object Storage.\n",
    "# Install torch and torchvision if not already installed\n",
    "!pip install torch torchvision oci\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import oci\n",
    "from oci.object_storage import ObjectStorageClient\n",
    "from oci.auth.signers import get_resource_principals_signer\n",
    "\n",
    "# Define the Generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Define the Discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Define training parameters\n",
    "nz = 100  # Size of the noise vector\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "images_to_generate = 20000  # Set the desired number of images to generate\n",
    "generated_images_count = 0  # Counter for generated images\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dict, transform=None):\n",
    "        self.image_dict = image_dict\n",
    "        self.transform = transform\n",
    "        self.images = list(image_dict.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Assuming 'image_dict' is already populated with images\n",
    "# image_dict = {}  # Populate this dictionary with your actual images\n",
    "\n",
    "dataset = ImageDataset(image_dict, transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize models, loss function, and optimizers\n",
    "netG = Generator(nz).to(device)\n",
    "netD = Discriminator().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Setup OCI Object Storage\n",
    "signer = get_resource_principals_signer()\n",
    "object_storage_client = ObjectStorageClient(config={}, signer=signer)\n",
    "\n",
    "# Define OCI bucket details\n",
    "namespace = \"orasenat*************\"  # Update with your actual namespace\n",
    "bucket_name = \"synthetic_images_bucket\"\n",
    "compartment_id = \"ocid1.compartment.oc1..**********************\"  # Update with your compartment OCID\n",
    "# Function to create a bucket if it doesn't exist\n",
    "def create_bucket(namespace, bucket_name, compartment_id):\n",
    "    try:\n",
    "        object_storage_client.get_bucket(namespace, bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    except oci.exceptions.ServiceError as e:\n",
    "        if e.status == 404:\n",
    "            try:\n",
    "                request = oci.object_storage.models.CreateBucketDetails(\n",
    "                    name=bucket_name,\n",
    "                    compartment_id=compartment_id,\n",
    "                    public_access_type='ObjectRead',\n",
    "                    storage_tier='Standard'\n",
    "                )\n",
    "                object_storage_client.create_bucket(namespace, request)\n",
    "                print(f\"Bucket {bucket_name} created.\")\n",
    "            except oci.exceptions.ServiceError as create_e:\n",
    "                if create_e.status == 409:\n",
    "                    print(f\"Bucket {bucket_name} already exists.\")\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "# Create the bucket if it doesn't exist\n",
    "create_bucket(namespace, bucket_name, compartment_id)\n",
    "\n",
    "# Training loop with stopping condition and unique filenames\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        if generated_images_count >= images_to_generate:\n",
    "            print(f\"Stopping training as {images_to_generate} images have been generated.\")\n",
    "            break\n",
    "\n",
    "        # Update Discriminator\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update Generator\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = netD(fake).view(-1)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Save generated images periodically with unique filenames to OCI Object Storage\n",
    "        with torch.no_grad():\n",
    "            fake = netG(fixed_noise).detach().cpu()\n",
    "        for j in range(fake.size(0)):\n",
    "            unique_filename = f'synthetic_{epoch}_{i}_{j}.png'\n",
    "            local_path = os.path.join('/tmp', unique_filename)\n",
    "            save_image(fake[j], local_path, normalize=True)\n",
    "            with open(local_path, 'rb') as f:\n",
    "                object_storage_client.put_object(namespace, bucket_name, unique_filename, f)\n",
    "            generated_images_count += 1\n",
    "\n",
    "        # Print progress\n",
    "        if i % 50 == 0:\n",
    "            print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}] '\n",
    "                  f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n",
    "                  f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
    "\n",
    "        # Stop condition if the desired number of images is reached\n",
    "        if generated_images_count >= images_to_generate:\n",
    "            break\n",
    "    if generated_images_count >= images_to_generate:\n",
    "        break\n",
    "\n",
    "# Function to count the number of image files in the OCI bucket\n",
    "def count_images_in_bucket(namespace, bucket_name):\n",
    "    objects = object_storage_client.list_objects(namespace, bucket_name)\n",
    "    return len(objects.data.objects)\n",
    "\n",
    "# Count the number of generated images\n",
    "num_images = count_images_in_bucket(namespace, bucket_name)\n",
    "print(f'Number of generated images: {num_images}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0691a-96b7-401f-ba7d-de108e237281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:automlx242_p38_gpu_x86_64_v1]",
   "language": "python",
   "name": "conda-env-automlx242_p38_gpu_x86_64_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
